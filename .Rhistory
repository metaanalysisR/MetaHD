library(usethis)
usethis::use_rcpp()
usethis::use_rcpp()
usethis::use_rcpp()
usethis::use_rcpp_armadillo()
library(devtools)
devtools::clean_dll()  # Clean previous builds
devtools::document()   # Generate documentation
library(devtools)
devtools::clean_dll()  # Clean previous builds
devtools::document()   # Generate documentation
devtools::build()      # Build the package
devtools::install()    # Install the package
library(roxygen2)
rm(list = c("cpp_XtVX"))
devtools::load_all()
rm(list = c("cpp_XtVX"))
devtools::load_all()
rm(list = c("cpp_XtVX"))
library(MetaHD)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(MetaHD)
realdata
library(matrixcalc)
library(RcppArmadillo)
devtools::build()
library(MetaHD)
library(MetaHD)
realdata
install.packages("htmltools")
install.packages("htmltools")
packageVersion("htmltools")
packageVersion("htmltools")
packageVersion("htmltools")
library(MetaHD)
dir.create("C:/Users/21460438/OneDrive - LA TROBE UNIVERSITY/Documents/MetaHD/inst/include", recursive = TRUE)
devtools::document("C:/Users/21460438/OneDrive - LA TROBE UNIVERSITY/Documents/MetaHD")
devtools::build("C:/Users/21460438/OneDrive - LA TROBE UNIVERSITY/Documents/MetaHD")
library(MetaHD)
devtools::clean_dll()  # Clean previous builds
library(MetaHD)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(corpcor)
library(dplyr)
library(MASS)
library(Matrix)
library(MetaHD)
library(corpcor)
library(dplyr)
library(MASS)
library(Matrix)
library(matrixcalc)
library(metafor)
library(tidyr)
GCLC_data <- realdata$all
View(GCLC_data)
# Group data by "Study" and "Group" and get statistical summaries for all the metabolites. Then arrange them by "Group"
GCLC_sum_data <- GCLC_data %>% group_by(Study,Group) %>%
summarise_each(funs(Mean = mean, Sd = sd, N = n())) %>%
arrange(desc(Group))
View(GCLC_sum_data)
# Group data by "Study" and "Group" and get statistical summaries for all the metabolites. Then arrange them by "Group"
GCLC_sum_data <- GCLC_data %>% group_by(Study,Group) %>%
across(list(Mean = mean, Sd = sd, N = n())) %>%
arrange(desc(Group))
# Group data by "Study" and "Group" and get statistical summaries for all the metabolites. Then arrange them by "Group"
GCLC_sum_data <- GCLC_data %>% group_by(Study,Group) %>%
summarise_each(funs(Mean = mean, Sd = sd, N = n())) %>%
arrange(desc(Group))
# Group data by "Study" and "Group" and get statistical summaries for all the metabolites. Then arrange them by "Group"
GCLC_sum_data <- GCLC_data %>% group_by(Study,Group) %>%
summarise(across(everything(), list(Mean = mean, Sd = sd, N = n())))%>%
arrange(desc(Group))
# Group data by "Study" and "Group" and get statistical summaries for all the metabolites. Then arrange them by "Group"
GCLC_sum_data <- GCLC_data %>% group_by(Study,Group) %>%
summarise_each(funs(Mean = mean, Sd = sd, N = n())) %>%
arrange(desc(Group))
# Remove "Study" and "Group" columns from the data frame
GCLC_stat_data <- as.data.frame(GCLC_sum_data[-c(1,2)])
View(GCLC_stat_data)
# Defining the number of metabolites
N <- (ncol(GCLC_stat_data))/3
# Extracting the metabolite names
GCLC_var_names <- names(GCLC_data[-c(1,2)])
# Calculating effect sizes and associated variances
meta.data <- list()
for (i in 1:N) {
meta.data[[i]] <- escalc(measure = "ROM",
m1i = GCLC_stat_data[1:2,i] ,
m2i = GCLC_stat_data[3:4,i],
n1i = GCLC_stat_data[1:2,i+(2*N)],
n2i = GCLC_stat_data[3:4,i+(2*N)],
sd1i = GCLC_stat_data[1:2,i+(N)],
sd2i = GCLC_stat_data[3:4,i+(N)],
append = FALSE)
}
# Creating dataframes of effect sizes and associated variances
effect_size <- list()
variance <- list()
for (i in 1:N) {
effect_size[[i]] <- meta.data[[i]][1]
variance[[i]] <- meta.data[[i]][2]
}
GCLC_Effects <- as.data.frame(effect_size)
GCLC_Variance <- as.data.frame(variance)
names(GCLC_Effects) <- GCLC_var_names
names(GCLC_Variance) <- GCLC_var_names
View(GCLC_Effects)
View(GCLC_Variance)
realdata$effects
realdata$effects
GCLC_Effects
# Define no. of outcomes/metabolites
N <- 30
# Define no. of studies
K <- 12
# Randomly choose true effect sizes for the outcomes
set.seed(2023)
theta <- sample(1:5,N,replace = TRUE)
# Define metabolite names using letters of the English alphabet
var_names <- LETTERS[1:N]
var_names[27] <- "AA"
var_names[28] <- "BB"
var_names[29] <- "CC"
var_names[30] <- "DD"
# Define within-study variances
set.seed(2023)
Sk_var_mat <- exp(matrix(rnorm(N*K,mean = -1.5 ,sd = 1),nrow = K,ncol = N))
colnames(Sk_var_mat) <- var_names
# Define between-study variances
set.seed(2023)
Psi_var <- exp(rnorm(N,mean = -5.5 ,sd = 1.5))
# Set between study correlations
set.seed(2023)
bscor <- c()
for (i in 1:((N*(N-1))/2)) {
repeat {
bscor[i] <- rnorm(1, mean = 0.25, sd = 0.1)
if (bscor[i] > 1 || bscor[i] < -1) {
# If the value is not in between -1 and 1, generate a new one
next
} else {
break  # Value satisfies the criteria, exit the repeat loop
}
}
}
# Set within-study correlations
wscor <- data.frame()
for (k in 1:K) {
for (i in 1:((N*(N-1))/2)) {
repeat {
wscor[k,i] <- rnorm(1, mean = 0.9, sd = 0.1)
if (wscor[k,i] > 1 || wscor[k,i] < -1) {
# If the value is not in between -1 and 1, generate a new one
next
} else {
break  # Value satisfies the criteria, exit the repeat loop
}
}
}
}
# Setting the between-study co-variance matrix across the outcomes (Psi)
Psi <- getCovMat(sqrt(Psi_var),bscor) #getCovMat is a function defined in MetaHD package
library(MetaHD)
# Read the data
GCLC_data <- realdata$all
# Group data by "Study" and "Group" and get statistical summaries for all the metabolites. Then arrange them by "Group"
GCLC_sum_data <- GCLC_data %>% group_by(Study,Group) %>%
summarise_each(funs(Mean = mean, Sd = sd, N = n())) %>%
arrange(desc(Group))
# Remove "Study" and "Group" columns from the data frame
GCLC_stat_data <- as.data.frame(GCLC_sum_data[-c(1,2)])
# Counting the number of metabolites
N <- (ncol(GCLC_stat_data))/3
# Extracting the metabolite names
GCLC_var_names <- names(GCLC_data[-c(1,2)])
# Calculating effect sizes and associated variances
meta.data <- list()
for (i in 1:N) {
meta.data[[i]] <- escalc(measure = "ROM",
m1i = GCLC_stat_data[1:2,i] ,
m2i = GCLC_stat_data[3:4,i],
n1i = GCLC_stat_data[1:2,i+(2*N)],
n2i = GCLC_stat_data[3:4,i+(2*N)],
sd1i = GCLC_stat_data[1:2,i+(N)],
sd2i = GCLC_stat_data[3:4,i+(N)],
append = FALSE)
}
# Creating dataframes of effect sizes and associated variances
effect_size <- list()
variance <- list()
for (i in 1:N) {
effect_size[[i]] <- meta.data[[i]][1]
variance[[i]] <- meta.data[[i]][2]
}
GCLC_Effects <- as.data.frame(effect_size)
GCLC_Variance <- as.data.frame(variance)
names(GCLC_Effects) <- GCLC_var_names
names(GCLC_Variance) <- GCLC_var_names
Effects <- realdata$effects
Variances <- realdata$var
study <- unique(GCLC_data$Study)
K <- length(study)
var_df <- data.frame(Variances, study=study)
var_df_long <- gather(var_df, metabolite, var_est,
met1:met14,
factor_key=TRUE)
sd_split <- split(sqrt(var_df_long$var_est),var_df_long$study)
Sk <- list()
wscormat.shrink <- list()
split_data <- split(GCLC_data,GCLC_data$Study)
for (k in 1:K) {
# calculate within-study correlation from real data
wscormat.shrink[[k]] <- estimateCorMat(log(split_data[[k]][,3:16])) #estimateCorMat is a function defined in MetaHD package
# calculating within-study covariance matrices
Sk[[k]] <- getCovMat(sd_split[[k]],wscormat.shrink[[k]]) #getCovMat is a function defined in MetaHD package
# checking for positive definiteness
if (!is.positive.definite(Sk[[k]])) {
Sk[[k]] <- as.matrix(nearPD(Sk[[k]],keepDiag = TRUE)$mat)
}
}
study <- unique(GCLC_data$Study)
K <- length(study)
var_df <- data.frame(Variances, study=study)
var_df_long <- gather(var_df, metabolite, var_est,
met1:met14,
factor_key=TRUE)
sd_split <- split(sqrt(var_df_long$var_est),var_df_long$study)
Sk <- list()
wscormat.shrink <- list()
split_data <- split(GCLC_data,GCLC_data$Study)
for (k in 1:K) {
# calculate within-study correlation from real data
wscormat.shrink[[k]] <- MetaHD:::estimateCorMat(log(split_data[[k]][,3:16]))
# calculating within-study covariance matrices
Sk[[k]] <- MetaHD:::estimateCorMat(sd_split[[k]],wscormat.shrink[[k]])
# checking for positive definiteness
if (!is.positive.definite(Sk[[k]])) {
Sk[[k]] <- as.matrix(nearPD(Sk[[k]],keepDiag = TRUE)$mat)
}
}
study <- unique(GCLC_data$Study)
K <- length(study)
var_df <- data.frame(Variances, study=study)
var_df_long <- gather(var_df, metabolite, var_est,
met1:met14,
factor_key=TRUE)
sd_split <- split(sqrt(var_df_long$var_est),var_df_long$study)
Sk <- list()
wscormat.shrink <- list()
split_data <- split(GCLC_data,GCLC_data$Study)
for (k in 1:K) {
# calculate within-study correlation from real data
wscormat.shrink[[k]] <- MetaHD:::estimateCorMat(log(split_data[[k]][,3:16]))
# calculating within-study covariance matrices
Sk[[k]] <- MetaHD:::getCovMat(sd_split[[k]],wscormat.shrink[[k]])
# checking for positive definiteness
if (!is.positive.definite(Sk[[k]])) {
Sk[[k]] <- as.matrix(nearPD(Sk[[k]],keepDiag = TRUE)$mat)
}
}
Y <- as.matrix(Effects)
Slist <- Sk
## MULTIVARIATE RANDOM-EFFECTS META-ANALYSIS, ESTIMATED WITH REML
model <- MetaHD(Y, Slist, method = "reml", bscov = "unstructured")
model$estimate
model$pVal
# Define no. of outcomes/metabolites
N <- 30
# Define no. of studies
K <- 12
# Randomly choose true effect sizes for the outcomes
set.seed(2023)
theta <- sample(1:5,N,replace = TRUE)
# Define metabolite names using letters of the English alphabet
var_names <- LETTERS[1:N]
var_names[27] <- "AA"
var_names[28] <- "BB"
var_names[29] <- "CC"
var_names[30] <- "DD"
# Define within-study variances
set.seed(2023)
Sk_var_mat <- exp(matrix(rnorm(N*K,mean = -1.5 ,sd = 1),nrow = K,ncol = N))
colnames(Sk_var_mat) <- var_names
# Define between-study variances
set.seed(2023)
Psi_var <- exp(rnorm(N,mean = -5.5 ,sd = 1.5))
# Set between study correlations
set.seed(2023)
bscor <- c()
for (i in 1:((N*(N-1))/2)) {
repeat {
bscor[i] <- rnorm(1, mean = 0.25, sd = 0.1)
if (bscor[i] > 1 || bscor[i] < -1) {
# If the value is not in between -1 and 1, generate a new one
next
} else {
break  # Value satisfies the criteria, exit the repeat loop
}
}
}
# Set within-study correlations
wscor <- data.frame()
for (k in 1:K) {
for (i in 1:((N*(N-1))/2)) {
repeat {
wscor[k,i] <- rnorm(1, mean = 0.9, sd = 0.1)
if (wscor[k,i] > 1 || wscor[k,i] < -1) {
# If the value is not in between -1 and 1, generate a new one
next
} else {
break  # Value satisfies the criteria, exit the repeat loop
}
}
}
}
# Setting the between-study co-variance matrix across the outcomes (Psi)
Psi <- MetaHD:::getCovMat(sqrt(Psi_var),bscor)
if (!is.positive.definite(Psi)) {
Psi <- as.matrix(nearPD(Psi,keepDiag = TRUE,maxit = 500)$mat)
}
row.names(Psi)<-colnames(Psi)<-var_names
# Setting the within-study covariance matrices across the outcomes (Sk)
# As a data frame in long format
Sk_var_df <- data.frame(Sk_var_mat,
study=1:K)
Sk_var_df_long <- gather(Sk_var_df, metabolite, var_est,
all_of(var_names),
factor_key=TRUE)
# Split into No. of studies
Sk_sd <- split(sqrt(Sk_var_df_long$var_est),Sk_var_df_long$study)
# Obtain Sk for each study
Sk <- list()
for (k in 1:K) {
Sk[[k]] <- MetaHD:::getCovMat(Sk_sd[[k]],wscor[k,])
if (!is.positive.definite(Sk[[k]])) {
Sk[[k]] <- as.matrix(nearPD(Sk[[k]],keepDiag = TRUE,maxit = 500)$mat)
}
}
# Generating estimated treatment effects from the multivariate model `nsim' times
nsim <- 1000
Y1 <- list()
for (j in 1:nsim) {
set.seed(2023+j)
Yk <- list()
tildethetak <- list()
for (k in 1:K) {
tildethetak[[k]] <- mvrnorm(mu = theta, Sigma = Psi)
Yk[[k]] <- mvrnorm(mu = tildethetak[[k]], Sigma = Sk[[k]])
}
Y1[[j]] <- as.data.frame(Yk)
colnames(Y1[[j]]) <- paste("study_",c(1:K),sep="")
Y1[[j]] <- t(Y1[[j]])
}
Y1[[1]]
Effects <- simdata.1$effects
WSVar <- simdata.1$wsvar
WSCor <- simdata.1$wscor # Upper traingular elements
## Create within-study covariance matrices using WSVar and WSCor
Sk_var_df_1 <- data.frame(WSVar,study=1:K)
Sk_var_df_long_1 <- gather(Sk_var_df_1, metabolite, var_est,
all_of(var_names),
factor_key=TRUE)
Sk_sd_1 <- split(sqrt(Sk_var_df_long_1$var_est),Sk_var_df_long_1$study)
Sk_1 <- list()
for (k in 1:K) {
Sk_1[[k]] <- MetaHD:::getCovMat(Sk_sd_1[[k]],WSCor[k,])
if (!is.positive.definite(Sk_1[[k]])) {
Sk_1[[k]] <- as.matrix(nearPD(Sk_1[[k]],keepDiag = TRUE,maxit = 500)$mat)
}
}
Effects
View(Effects)
Y1[[1]]
Y <- as.matrix(unname(Y1[[1]]))
Slist <- Sk
## MULTIVARIATE RANDOM-EFFECTS META-ANALYSIS FOR SIMULATED DATA (HIGH-WITHIN STUDY CORRELATIONS), ESTIMATED WITH REML
model_1 <- MetaHD(Y,
Slist,
method = "reml",
bscov = "unstructured")
model_1$estimate # TRUE VALUES ARE: 5, 1, 3, 2, 4, 2, 1, 1, 5, 1, 1, 5, 5, 2, 3, 5, 4, 5, 1, 1, 2, 5, 1, 2, 1, 5, 4, 1, 4, 2
source("~/PhD Work/metahd-github version edited/Examples/ExampleCode.R")
Y <- as.matrix(Effects)
Slist <- Sk_1
## MULTIVARIATE RANDOM-EFFECTS META-ANALYSIS FOR SIMULATED DATA (HIGH-WITHIN STUDY CORRELATIONS), ESTIMATED WITH REML
model_1 <- MetaHD(Y,
Slist,
method = "reml",
bscov = "unstructured")
model_1$estimate # TRUE VALUES ARE: 5, 1, 3, 2, 4, 2, 1, 1, 5, 1, 1, 5, 5, 2, 3, 5, 4, 5, 1, 1, 2, 5, 1, 2, 1, 5, 4, 1, 4, 2
simdata.2$effects
View(Effects)
Y1[[2]]
Y1[[5]]
Y1[[10]]
Y1[[3]]
Y1[[4]]
simdata.2$effects
library(MetaHD)
usethis::use_vignette("my-vignette")
library(MetaHD)
devtools::build()
devtools::build("C:\\Users\\21460438\\OneDrive - LA TROBE UNIVERSITY\\Documents\\MetaHD")
devtools::check("C:\\Users\\21460438\\OneDrive - LA TROBE UNIVERSITY\\Documents\\MetaHD")
devtools::check("C:\\Users\\21460438\\OneDrive - LA TROBE UNIVERSITY\\Documents\\MetaHD",manual = TRUE)
